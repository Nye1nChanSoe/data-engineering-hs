{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95ef430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a8ccd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Spark Context Info =====\n",
      "App Name      : Test Spark\n",
      "Master        : local[2]\n",
      "Application ID: local-1758076362518\n",
      "UI Web URL    : http://10.197.178.163:4040\n",
      "Version       : 4.0.1\n",
      "Python Ver    : 3.11\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Test Spark\")\n",
    "    # run with 2 threads\n",
    "    .master(\"local[2]\")\n",
    "    # use arrow\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    # use hdfs\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://127.0.0.1:9000\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark_context = spark.sparkContext.getOrCreate()\n",
    "\n",
    "print(\"\\n===== Spark Context Info =====\")\n",
    "print(f\"App Name      : {spark_context.appName}\")\n",
    "print(f\"Master        : {spark_context.master}\")\n",
    "print(f\"Application ID: {spark_context.applicationId}\")\n",
    "print(f\"UI Web URL    : {spark_context.uiWebUrl}\")\n",
    "print(f\"Version       : {spark_context.version}\")\n",
    "print(f\"Python Ver    : {spark_context.pythonVer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555285b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+\n",
      "|   name|age|         city|\n",
      "+-------+---+-------------+\n",
      "|  Alice| 29|     New York|\n",
      "|    Bob| 35|San Francisco|\n",
      "|Charlie| 40|       London|\n",
      "|  Diana| 23|       Berlin|\n",
      "|  Ethan| 31|       Sydney|\n",
      "+-------+---+-------------+\n",
      "\n",
      "== Parsed Logical Plan ==\n",
      "LogicalRDD [name#27, age#28, city#29], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "name: string, age: int, city: string\n",
      "LogicalRDD [name#27, age#28, city#29], false\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "LogicalRDD [name#27, age#28, city#29], false\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Scan ExistingRDD[name#27,age#28,city#29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"name\", StringType(), False),\n",
    "        StructField(\"age\", IntegerType(), False),\n",
    "        StructField(\"city\", StringType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        {\"name\": \"Alice\", \"age\": 29, \"city\": \"New York\"},\n",
    "        {\"name\": \"Bob\", \"age\": 35, \"city\": \"San Francisco\"},\n",
    "        {\"name\": \"Charlie\", \"age\": 40, \"city\": \"London\"},\n",
    "        {\"name\": \"Diana\", \"age\": 23, \"city\": \"Berlin\"},\n",
    "        {\"name\": \"Ethan\", \"age\": 31, \"city\": \"Sydney\"},\n",
    "    ],\n",
    "    schema,\n",
    ")\n",
    "\n",
    "\n",
    "df.show()\n",
    "df.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "618c8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").parquet(\"hdfs:///users/nyeinchan/hdfs-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc2cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = spark.read.parquet(\"hdfs:///users/nyeinchan/hdfs-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f65e7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------------+\n",
      "|   name|age|         city|\n",
      "+-------+---+-------------+\n",
      "|Charlie| 40|       London|\n",
      "|  Diana| 23|       Berlin|\n",
      "|  Ethan| 31|       Sydney|\n",
      "|  Alice| 29|     New York|\n",
      "|    Bob| 35|San Francisco|\n",
      "+-------+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3108af21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+---------+---------+--------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|icao_code|iata_code|gps_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+---------+---------+--------+----------+--------------------+\n",
      "|  00A|     heliport|   Total RF Heliport|          11|       NA|         US|     US-PA|    Bensalem|     null|     null|    K00A|       00A|40.070985, -74.93...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|     null|     null|    00AA|      00AA|38.704022, -101.4...|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|     null|     null|    00AK|      00AK|59.947733, -151.6...|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|     null|     null|    00AL|      00AL|34.86479949951172...|\n",
      "| 00AN|small_airport|Katmai Lodge Airport|          80|       NA|         US|     US-AK| King Salmon|     null|     null|    00AN|      00AN|59.093287, -156.4...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+---------+---------+--------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- icao_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .option(\"inferSchema\", True)\n",
    "    .csv(\"hdfs:///users/nyeinchan/hdfs-data/airport/airport_codes.csv\")\n",
    ")\n",
    "\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
