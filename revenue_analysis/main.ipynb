{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c072bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType,\n",
    "    DateType,\n",
    "    BooleanType,\n",
    "    TimestampType,\n",
    "    DoubleType,\n",
    ")\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    to_timestamp,\n",
    "    to_date,\n",
    "    when,\n",
    "    broadcast,\n",
    "    count,\n",
    "    sum as spark_sum,\n",
    "    count_distinct,\n",
    ")\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdb7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Revenue Analysis\")\n",
    "    .master(\"local[8]\")\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "    # .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://127.0.0.1:9000\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark_context = spark.sparkContext.getOrCreate()\n",
    "\n",
    "print(\"\\n===== Spark Context Info =====\")\n",
    "print(f\"App Name      : {spark_context.appName}\")\n",
    "print(f\"Master        : {spark_context.master}\")\n",
    "print(f\"Application ID: {spark_context.applicationId}\")\n",
    "print(f\"UI Web URL    : {spark_context.uiWebUrl}\")\n",
    "print(f\"Version       : {spark_context.version}\")\n",
    "print(f\"Python Ver    : {spark_context.pythonVer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83febe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 1 data/items.jsonl | jq \"keys_unsorted\" \n",
    "!head -n 1 data/users.jsonl | jq \"keys_unsorted\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96050061",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -c data/events/part-00.jsonl.gz | head -n 1 | jq \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = StructType(\n",
    "    [\n",
    "        StructField(\"item_id\", IntegerType(), False),\n",
    "        StructField(\"category\", StringType(), False),\n",
    "        StructField(\"tags\", ArrayType(StringType()), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "user_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), False),\n",
    "        StructField(\"signup_date\", DateType(), False),\n",
    "        StructField(\"plan\", StringType(), False),\n",
    "        StructField(\"country\", StringType(), False),\n",
    "        StructField(\"marketing_opt_in\", BooleanType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "event_schema = StructType(\n",
    "    [\n",
    "        StructField(\"ts\", TimestampType(), False),\n",
    "        StructField(\"event\", StringType(), False),\n",
    "        StructField(\"user_id\", IntegerType(), False),\n",
    "        StructField(\"item_id\", IntegerType(), False),\n",
    "        StructField(\n",
    "            \"context\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"country\", StringType(), False),\n",
    "                    StructField(\"device\", StringType(), False),\n",
    "                    StructField(\"locale\", StringType(), False),\n",
    "                    StructField(\"session_id\", StringType(), False),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\n",
    "            \"props\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"price\", DoubleType(), True),\n",
    "                    StructField(\"payment_method\", StringType(), True),\n",
    "                    StructField(\"dwell_ms\", IntegerType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\n",
    "            \"exp\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"ab_group\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfe0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = spark.read.schema(user_schema).json(\"data/users.jsonl\")\n",
    "df_items = spark.read.schema(items_schema).json(\"data/items.jsonl\")\n",
    "df_events = spark.read.schema(event_schema).json(\n",
    "    [\n",
    "        \"data/events/part-00.jsonl.gz\",\n",
    "        \"data/events/part-01.jsonl.gz\",\n",
    "        \"data/events/part-02.jsonl.gz\",\n",
    "        \"data/events/part-03.jsonl.gz\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"users | total - {df_users.count()} | partitions - {df_users.rdd.getNumPartitions()}\"\n",
    ")\n",
    "df_users.show(5)\n",
    "print(\n",
    "    f\"\\nitems | total - {df_items.count()} | partitions - {df_items.rdd.getNumPartitions()}\"\n",
    ")\n",
    "df_items.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = spark.read.schema(event_schema).json(\n",
    "    [\n",
    "        \"data/events/part-00.jsonl.gz\",\n",
    "        \"data/events/part-01.jsonl.gz\",\n",
    "        \"data/events/part-02.jsonl.gz\",\n",
    "        \"data/events/part-03.jsonl.gz\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"events | total - {df_events.count()} | partitions - {df_events.rdd.getNumPartitions()}\"\n",
    ")\n",
    "df_events.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = df_events.withColumn(\"timestamp\", to_timestamp(\"ts\")).withColumn(\n",
    "    \"date\", to_date(\"ts\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = (\n",
    "    df_events.withColumn(\n",
    "        \"revenue\",\n",
    "        when(col(\"event\") == \"purchase\", col(\"props.price\").cast(DoubleType()))\n",
    "        .otherwise(0.0)\n",
    "        .cast(DoubleType()),\n",
    "    )\n",
    ").filter(col(\"revenue\") >= 0.0)\n",
    "\n",
    "print(\n",
    "    f\"events | total - {df_events.count()} | partitions - {df_events.rdd.getNumPartitions()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8431ea",
   "metadata": {},
   "source": [
    "#### broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd8916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark shuffles both side of joins\n",
    "# shuffles -> computationally expension and i/o operations included\n",
    "# broadcast -> ships small tables to every executors\n",
    "# now executors can join locally with their respective partitions\n",
    "\n",
    "df_joined = df_events.join(broadcast(df_items), on=\"item_id\", how=\"left\").join(\n",
    "    broadcast(df_users), df_events.user_id == df_users.id, how=\"left\"\n",
    ")\n",
    "\n",
    "df_joined.explain(\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregate = df_joined.groupBy(\"date\", \"country\", \"category\").agg(\n",
    "    count(\"*\").alias(\"total_events\"),\n",
    "    count(when(col(\"event\") == \"purchase\", 1)).alias(\"num_purchases\"),\n",
    "    spark_sum(\"revenue\").alias(\"total_revenue\"),\n",
    "    count_distinct(\"user_id\").alias(\"unique_users\"),\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"aggregations | total - {df_aggregate.count()} | partitions - {df_aggregate.rdd.getNumPartitions()}\"\n",
    ")\n",
    "df_aggregate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172543f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window.partitionBy(\"country\", \"category\").orderBy(\"date\").rowsBetween(-6, 0)\n",
    "\n",
    "df_final = df_aggregate.withColumn(\"revenue_7d\", spark_sum(\"total_revenue\").over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one folder per date partitionBy('date')\n",
    "\n",
    "df_final.write.mode(\"overwrite\").partitionBy(\"date\").parquet(\"out/daily_kpi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf747d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = spark.read.parquet(\"out/daily_kpi/date=2025-10-23\")\n",
    "\n",
    "print(\n",
    "    f\"out/daily_kpi/date=2025-10-23 | total - {df_sample.count()} | partitions - {df_sample.rdd.getNumPartitions()}\"\n",
    ")\n",
    "df_sample.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a2f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: repartition findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
